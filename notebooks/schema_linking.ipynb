{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema-Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "@article{pourreza2024dts, title={DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models}, author={Pourreza, Mohammadreza and Rafiei, Davood}, journal={arXiv preprint arXiv:2402.01117}, year={2024} }\n",
    "\n",
    "https://github.com/MohammadrezaPourreza/DTS-SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_table_names(db_uri: str) -> list[str]:\n",
    "    conn = sqlite3.connect(db_uri)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    table_names = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table_name[0] for table_name in table_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_schema_with_samples(\n",
    "    db_uri: str, table_name: str, sample_limit: int = 0, columns_description: dict[str, str] = {}\n",
    ") -> str:\n",
    "    conn = sqlite3.connect(db_uri)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch table schema\n",
    "    cursor.execute(f\"PRAGMA table_info(`{table_name}`);\")\n",
    "    columns = cursor.fetchall()\n",
    "    cursor.execute(f\"PRAGMA foreign_key_list(`{table_name}`);\")\n",
    "    foreign_keys = cursor.fetchall()\n",
    "    cursor.execute(f\"PRAGMA index_list(`{table_name}`);\")\n",
    "    primary_key_indices = cursor.fetchall()\n",
    "    primary_key_columns = []\n",
    "\n",
    "    for index_info in primary_key_indices:\n",
    "        index_name = index_info[1]\n",
    "        cursor.execute(f\"PRAGMA index_info(`{index_name}`);\")\n",
    "        index_columns = cursor.fetchall()\n",
    "        primary_key_columns.extend(column[2] for column in index_columns)\n",
    "\n",
    "    # Construct CREATE TABLE statement\n",
    "    schema_str = f\"CREATE TABLE `{table_name}` (\\n\"\n",
    "    for column in columns:\n",
    "        column_name = column[1]\n",
    "        data_type = column[2]\n",
    "        schema_str += f\"  {column_name} {data_type}\"\n",
    "        if column_name in primary_key_columns:\n",
    "            schema_str += \" PRIMARY KEY\"\n",
    "        for foreign_key in foreign_keys:\n",
    "            if column_name == foreign_key[3]:\n",
    "                schema_str += f\" REFERENCES {foreign_key[2]}({foreign_key[4]})\"\n",
    "        if column_name in columns_description:\n",
    "            schema_str += f\" -- '{columns_description[column_name]}'\"\n",
    "\n",
    "        schema_str += \",\\n\"\n",
    "    schema_str = schema_str.rstrip(\",\\n\")\n",
    "    schema_str += \"\\n);\\n\"\n",
    "\n",
    "    \n",
    "    cursor.execute(f\"SELECT * FROM `{table_name}` LIMIT {sample_limit};\")\n",
    "    sample_rows = cursor.fetchall()\n",
    "\n",
    "    if len(sample_rows) > 0:\n",
    "        schema_str += f\"Sample rows from `{table_name}`:\\n\"\n",
    "        for row in sample_rows:\n",
    "            formatted_row = \", \".join(str(item) for item in row)\n",
    "            schema_str += f\"{formatted_row}\\n\"\n",
    "\n",
    "    conn.close()\n",
    "    return schema_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "  return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_descriptions(db_path: str, table_name: str) -> list[str]:\n",
    "    if not os.path.exists(f\"{db_path}/database_description/{table_name}.csv\"):\n",
    "        return {}\n",
    "    try:\n",
    "        df = pd.read_csv(f\"{db_path}/database_description/{table_name}.csv\")\n",
    "    except Exception:\n",
    "        return {}\n",
    "    if \"column_description\" not in df.columns or \"value_description\" not in df.columns:\n",
    "        return {}\n",
    "    columns_description = {}\n",
    "    for index, row in df.iterrows():\n",
    "        if np.nan != row[\"column_description\"] and pd.notna(row[\"column_description\"]):\n",
    "            columns_description[row[\"original_column_name\"]] = remove_spaces(row[\"column_description\"])\n",
    "            if np.nan != row[\"value_description\"] and pd.notna(row[\"value_description\"]):\n",
    "                columns_description[row[\"original_column_name\"]] += f\" has values: ({remove_spaces(row['value_description'])})\"\n",
    "    return columns_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schema_for_instance(row, base_databases_dir):\n",
    "    db_id = row['db_id']\n",
    "    \n",
    "    # Set up database paths\n",
    "    db_uri = f\"{base_databases_dir}/{db_id}/{db_id}.sqlite\"\n",
    "    \n",
    "    # Get table names and build schema\n",
    "    table_names = get_all_table_names(db_uri)\n",
    "    database_schema = \"\"\n",
    "    \n",
    "    for table_name in table_names:\n",
    "        columns_description = load_descriptions(db_id, table_name)\n",
    "        schema = get_table_schema_with_samples(db_uri, table_name, 0, columns_description)\n",
    "        database_schema += schema + \"\\n\"\n",
    "    \n",
    "    return database_schema.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATASET_DIR = \"../dataset/dev.json\"\n",
    "BASE_DABATASES_DIR =  \"../dataset/dev_databases/\"\n",
    "OUTPUT_FILENAME = \"dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(BASE_DATASET_DIR)\n",
    "row = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each row and generate schema for each instance\n",
    "for idx, row in df.iterrows():\n",
    "# Generate the schema for the current row\n",
    "    database_schema = generate_schema_for_instance(row, BASE_DABATASES_DIR)\n",
    "        \n",
    "    # Add the generated schema to a new field 'database_schema' in the row\n",
    "    df.at[idx, 'database_schema'] = database_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id                                                        0\n",
       "db_id                                             california_schools\n",
       "question           What is the highest eligible free rate for K-1...\n",
       "evidence           Eligible free rate for K-12 = `Free Meal Count...\n",
       "SQL                SELECT `Free Meal Count (K-12)` / `Enrollment ...\n",
       "difficulty                                                    simple\n",
       "database_schema    CREATE TABLE `frpm` (\\n  CDSCode TEXT PRIMARY ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Specify the file name\n",
    "file_name = OUTPUT_FILENAME\n",
    "\n",
    "# Convert DataFrame to dictionary\n",
    "data = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
